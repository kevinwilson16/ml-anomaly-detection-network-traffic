{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "957d64f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV files found: 8\n",
      "- Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\n",
      "- Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv\n",
      "- Friday-WorkingHours-Morning.pcap_ISCX.csv\n",
      "- Monday-WorkingHours.pcap_ISCX.csv\n",
      "- Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_DIR = Path(\"../data/cicids2017/raw\")\n",
    "\n",
    "csv_files = list(DATA_DIR.glob(\"*.csv\"))\n",
    "print(\"CSV files found:\", len(csv_files))\n",
    "for f in csv_files[:5]:\n",
    "    print(\"-\", f.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f25c31ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x96 in position 22398: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeDecodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m dfs = []\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m csv_files:\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     df.columns = df.columns.str.strip()  \u001b[38;5;66;03m# fix CIC whitespace bug\u001b[39;00m\n\u001b[32m      5\u001b[39m     dfs.append(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\OneDrive - Heriot-Watt University\\Desktop\\ml-anomaly-detection-network-traffic\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:873\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, skip_blank_lines, parse_dates, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m    861\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m    862\u001b[39m     dialect,\n\u001b[32m    863\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m    869\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m    870\u001b[39m )\n\u001b[32m    871\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\OneDrive - Heriot-Watt University\\Desktop\\ml-anomaly-detection-network-traffic\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:306\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mparser\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\OneDrive - Heriot-Watt University\\Desktop\\ml-anomaly-detection-network-traffic\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1947\u001b[39m, in \u001b[36mTextFileReader.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m   1940\u001b[39m nrows = validate_integer(\u001b[33m\"\u001b[39m\u001b[33mnrows\u001b[39m\u001b[33m\"\u001b[39m, nrows)\n\u001b[32m   1941\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1942\u001b[39m     \u001b[38;5;66;03m# error: \"ParserBase\" has no attribute \"read\"\u001b[39;00m\n\u001b[32m   1943\u001b[39m     (\n\u001b[32m   1944\u001b[39m         index,\n\u001b[32m   1945\u001b[39m         columns,\n\u001b[32m   1946\u001b[39m         col_dict,\n\u001b[32m-> \u001b[39m\u001b[32m1947\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[attr-defined]\u001b[39;49;00m\n\u001b[32m   1948\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnrows\u001b[49m\n\u001b[32m   1949\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1950\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1951\u001b[39m     \u001b[38;5;28mself\u001b[39m.close()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kevin\\OneDrive - Heriot-Watt University\\Desktop\\ml-anomaly-detection-network-traffic\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:215\u001b[39m, in \u001b[36mCParserWrapper.read\u001b[39m\u001b[34m(self, nrows)\u001b[39m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    214\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.low_memory:\n\u001b[32m--> \u001b[39m\u001b[32m215\u001b[39m         chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reader\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_low_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    216\u001b[39m         \u001b[38;5;66;03m# destructive to chunks\u001b[39;00m\n\u001b[32m    217\u001b[39m         data = _concatenate_chunks(chunks, \u001b[38;5;28mself\u001b[39m.names)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:832\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.read_low_memory\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:897\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._read_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:868\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:885\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:2076\u001b[39m, in \u001b[36mpandas._libs.parsers.raise_parser_error\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m<frozen codecs>:325\u001b[39m, in \u001b[36mBufferedIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    323\u001b[39m     \u001b[38;5;66;03m# decode input (taking the buffer into account)\u001b[39;00m\n\u001b[32m    324\u001b[39m     data = \u001b[38;5;28mself\u001b[39m.buffer + \u001b[38;5;28minput\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m325\u001b[39m     (result, consumed) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_buffer_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    326\u001b[39m     \u001b[38;5;66;03m# keep undecoded input until the next call\u001b[39;00m\n\u001b[32m    327\u001b[39m     \u001b[38;5;28mself\u001b[39m.buffer = data[consumed:]\n",
      "\u001b[31mUnicodeDecodeError\u001b[39m: 'utf-8' codec can't decode byte 0x96 in position 22398: invalid start byte"
     ]
    }
   ],
   "source": [
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    df.columns = df.columns.str.strip()  # fix CIC whitespace bug\n",
    "    dfs.append(df)\n",
    "\n",
    "data = pd.concat(dfs, ignore_index=True)\n",
    "print(\"Merged shape:\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2c8dc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Replace infinities with NaN then drop missing\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mdata\u001b[49m.replace([np.inf, -np.inf], np.nan, inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      3\u001b[39m before = data.shape[\u001b[32m0\u001b[39m]\n\u001b[32m      4\u001b[39m data.dropna(inplace=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "# Replace infinities with NaN then drop missing\n",
    "data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "before = data.shape[0]\n",
    "data.dropna(inplace=True)\n",
    "after = data.shape[0]\n",
    "print(\"Rows removed:\", before - after)\n",
    "print(\"After cleaning:\", data.shape)\n",
    "\n",
    "print(\"Label column exists:\", \"Label\" in data.columns)\n",
    "data[\"Label\"].value_counts().head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5854ebfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m processed_dir.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m      4\u001b[39m out_path = processed_dir / \u001b[33m\"\u001b[39m\u001b[33mcicids2017_merged_clean.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m \u001b[43mdata\u001b[49m.to_csv(out_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mSaved to:\u001b[39m\u001b[33m\"\u001b[39m, out_path)\n",
      "\u001b[31mNameError\u001b[39m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "processed_dir = Path(\"../data/cicids2017/processed\")\n",
    "processed_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_path = processed_dir / \"cicids2017_merged_clean.csv\"\n",
    "data.to_csv(out_path, index=False)\n",
    "print(\"Saved to:\", out_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
